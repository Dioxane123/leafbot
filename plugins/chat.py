from openai import OpenAI
import os
import re
from datetime import datetime
from dotenv import load_dotenv
load_dotenv()

from melobot import PluginPlanner
from melobot.protocols.onebot.v11 import MessageEvent, on_message, Adapter, PrivateMsgChecker, GroupMsgChecker, GroupMessageEvent
from melobot.protocols.onebot.v11 import NodeSegment, ImageSegment, TextSegment, LevelRole, AtSegment, ReplySegment

# å»ºè®®å°†APIå¯†é’¥è®¾ç½®ä¸ºç¯å¢ƒå˜é‡ï¼Œç„¶åé€šè¿‡ os.getenv() è¯»å–
# åœ¨æ‚¨çš„ç»ˆç«¯ä¸­è¿è¡Œ:
# export OPENAI_API_KEY='your-api-key-here'
# client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
# å¦‚æœæ²¡æœ‰è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œä¹Ÿå¯ä»¥ç›´æ¥åœ¨ä»£ç ä¸­åˆå§‹åŒ–ï¼š
# client = OpenAI(api_key="sk-...")

class OpenAIConversation:
    """
    ä¸€ä¸ªä½¿ç”¨ OpenAI API å®ç°â€œæ°¸ä¹…å¯¹è¯â€çš„ç±»ã€‚
    """
    def __init__(self,
                api_key: str,
                model_name: str = "Qwen/Qwen2.5-72B-Instruct",
                history_threshold: int = 10,
                owner: int = 1204876262,
                character_instruction: str | None = None):
        """
        åˆå§‹åŒ–å¯¹è¯ç®¡ç†å™¨ã€‚
        
        å‚æ•°:
            api_key (str): æ‚¨çš„ OpenAI API å¯†é’¥ã€‚
            model_name (str): è¦ä½¿ç”¨çš„æ¨¡å‹åç§°
            history_threshold (int): å¯¹è¯å†å²çš„é˜ˆå€¼ï¼Œè§¦å‘è®°å¿†ç”Ÿæˆã€‚
            owner (int): å¯¹è¯çš„æ‰€æœ‰è€…IDã€‚
            character_instruction (str | None): è®¾å®šæ¨¡å‹çš„äººè®¾ã€‚
        """
        if not api_key:
            raise ValueError("API key cannot be empty.")

        self.client = OpenAI(api_key=api_key, 
                base_url="https://api.siliconflow.cn/v1")
        self.model_name = model_name
        # å†å²è®°å½•ç°åœ¨éµå¾ª OpenAI çš„æ ¼å¼
        self.history = []  # æ ¼å¼: [{'role': 'user' | 'assistant', 'content': text}]
        self.long_term_memory = ""
        self.history_threshold = history_threshold
        self.character_instruction = character_instruction
        self.owner = owner

    def _clean_response(self, text):
        """
        ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¸…æ´—æ¨¡å‹è¾“å‡ºçš„æ— å…³å‰ç¼€ã€‚
        """
        pattern = r"^\s*(å¥½çš„|å½“ç„¶|æ²¡é—®é¢˜|å¥½çš„ï¼Œ|å½“ç„¶ï¼Œ|ä»¥ä¸‹æ˜¯æ‘˜è¦|è¿™æ˜¯æ‘˜è¦|æ‘˜è¦å¦‚ä¸‹|Okay|Sure|Here is the summary)[:ï¼š,\s]*"
        cleaned_text = re.sub(pattern, '', text, flags=re.IGNORECASE).strip()
        return cleaned_text

    def _generate_memory(self, conversation_context):
        """
        ç”Ÿæˆæ‘˜è¦ã€‚
        """
        
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„å¯¹è¯æ‘˜è¦å·¥å…·ã€‚ä½ çš„ä»»åŠ¡æ˜¯é˜…è¯»ä¸€æ®µå¯¹è¯ï¼Œç„¶åç›´æ¥è¾“å‡ºæ‘˜è¦å†…å®¹ï¼Œä¸èƒ½æœ‰ä»»ä½•é¢å¤–çš„è¯è¯­æˆ–å‰ç¼€ã€‚

        [èŒƒä¾‹]
        è¾“å…¥:
        system:è¯·åˆ©ç”¨ä»¥ä¸‹èƒŒæ™¯ä¿¡æ¯ï¼ˆè¿™æ˜¯æˆ‘ä»¬ä¹‹å‰å¯¹è¯çš„æ‘˜è¦ï¼‰æ¥è‡ªç„¶åœ°å›ç­”æˆ‘çš„é—®é¢˜ã€‚
            è¯·ä¸è¦åœ¨å›ç­”ä¸­æåŠä½ å‚è€ƒäº†â€œæ‘˜è¦â€æˆ–â€œèƒŒæ™¯ä¿¡æ¯â€ã€‚

            --- èƒŒæ™¯ä¿¡æ¯ ---
            ç”¨æˆ·æ­¤å‰æåˆ°ä»–ä¸‹å‘¨å°±æ˜¯20å²ç”Ÿæ—¥ã€‚
            ---
        user: ä½ å¥½ï¼Œæˆ‘å«å¼ ä¼Ÿï¼Œæˆ‘æƒ³è®¢ä¸€å¼ å»ä¸Šæµ·çš„æœºç¥¨ã€‚
        assistant: å¥½çš„å¼ ä¼Ÿï¼Œè¯·é—®æ‚¨æƒ³ä»€ä¹ˆæ—¥æœŸå‡ºå‘å‘¢ï¼Ÿ
        user: ä¸‹å‘¨ä¸‰å§ã€‚
        è¾“å‡º:
        ç”¨æˆ·å«å¼ ä¼Ÿï¼Œæ­¤å‰æåˆ°ä¸‹å‘¨æ˜¯ä»–çš„20å²ç”Ÿæ—¥ï¼Œä»–è®¡åˆ’ä¸‹å‘¨ä¸‰å»ä¸Šæµ·ï¼Œéœ€è¦è®¢æœºç¥¨ã€‚

        [ç°åœ¨è½®åˆ°ä½ äº†]
        è¾“å…¥:
        {conversation_context}
        è¾“å‡º:
        """
        
        try:
            # ä½¿ç”¨ OpenAI API è°ƒç”¨
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}]
            )
            
            # è·å–å¹¶æ¸…æ´—å›å¤
            raw_memory = response.choices[0].message.content.strip()
            clean_memory = self._clean_response(raw_memory)
            
            # print(f"--- âœ… æ–°çš„é•¿æœŸè®°å¿†å·²ç”Ÿæˆï¼š---\n{clean_memory}\n")
            return clean_memory
        except Exception as e:
            # print(f"--- âŒ è°ƒç”¨ OpenAI API ç”Ÿæˆè®°å¿†æ—¶å‡ºé”™: {e} ---")
            return ""

    def chat(self, user_message):
        """
        ä¸æ¨¡å‹è¿›è¡Œä¸€æ¬¡å¯¹è¯ã€‚
        """
        # 1. æ„å»ºæœ¬æ¬¡è¯·æ±‚çš„æ¶ˆæ¯åˆ—è¡¨
        messages_for_chat = []

        # 2. åˆ©ç”¨ 'system' è§’è‰²æ¥ä¼ é€’é•¿æœŸè®°å¿†å’ŒæŒ‡ä»¤ï¼Œè¿™æ˜¯OpenAIçš„æ¨èåšæ³•
        if self.long_term_memory or os.path.isfile(".cache/chat/memory.txt"):
            if not self.long_term_memory:
                with open(f".cache/chat/memory_{self.owner}.txt", "a+") as memory_file:
                    self.long_term_memory = memory_file.read()
            system_instruction = f"""
            {self.character_instruction}\n
            è¯·åˆ©ç”¨ä»¥ä¸‹èƒŒæ™¯ä¿¡æ¯ï¼ˆè¿™æ˜¯æˆ‘ä»¬ä¹‹å‰å¯¹è¯çš„æ‘˜è¦ï¼‰æ¥è‡ªç„¶åœ°å›ç­”æˆ‘çš„é—®é¢˜ã€‚
            è¯·ä¸è¦åœ¨å›ç­”ä¸­æåŠä½ å‚è€ƒäº†â€œæ‘˜è¦â€æˆ–â€œèƒŒæ™¯ä¿¡æ¯â€ã€‚

            --- èƒŒæ™¯ä¿¡æ¯ ---
            {self.long_term_memory}
            ---
            """
            messages_for_chat.append({"role": "system", "content": system_instruction})
        else:
            messages_for_chat.append({"role": "system", "content": self.character_instruction})
        
        # 3. æ·»åŠ è¿‘æœŸå†å²
        messages_for_chat.extend(self.history)
        
        # 4. æ·»åŠ ç”¨æˆ·æœ€æ–°çš„æ¶ˆæ¯
        messages_for_chat.append({"role": "user", "content": user_message})

        # 5. è°ƒç”¨ OpenAI API
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages_for_chat
            )
            ai_response = self._clean_response(response.choices[0].message.content.strip())
        except Exception as e:
            ai_response = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†ä¸€ä¸ªé”™è¯¯: {e}"

        # 6. æ›´æ–°å®Œæ•´å¯¹è¯å†å²ï¼ˆåŒ…æ‹¬ç”¨æˆ·çš„æœ€æ–°æ¶ˆæ¯å’ŒAIçš„å›å¤ï¼‰
        self.history.append({"role": "user", "content": user_message})
        self.history.append({"role": "assistant", "content": ai_response})

        # 7. æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°é•¿æœŸè®°å¿†
        if len(self.history) / 2 >= self.history_threshold:
            # å°†å†å²è®°å½•è½¬æ¢ä¸ºçº¯æ–‡æœ¬ï¼Œæ³¨æ„ 'assistant' è§’è‰²
            context_to_summarize = "\n".join([f"{msg['role']}: {msg['content']}" for msg in self.history])
            
            new_memory = self._generate_memory(context_to_summarize)
            if new_memory:
                self.long_term_memory = f"{self.long_term_memory}\n{new_memory}".strip()
                # self.long_term_memory = f"{new_memory}".strip()
                os.makedirs(".cache/chat",exist_ok=True)
                with open(f".cache/chat/memory_{self.owner}.txt", "w") as memory_file:
                    memory_file.write(self.long_term_memory)
            self.history = []
            # print("\n--- ğŸ“œ è¿‘æœŸå†å²å·²æ¸…ç©ºå¹¶è½¬ä¸ºé•¿æœŸè®°å¿†ã€‚---\n")

        return ai_response


OWNER = int(os.getenv("OWNER"))
TEST_GROUP = [int(os.getenv("TEST_GROUP"))]
my_api_key = os.getenv("API_KEY")

conversation_owner = OpenAIConversation(api_key = my_api_key,
                                history_threshold = 10,
                                model_name = "deepseek-ai/DeepSeek-V3",
                                character_instruction="""
# è§’è‰²è®¾å®šï¼šå°å¶
*   **ä½ æ˜¯è°**ï¼šæˆ‘çš„ä¸“å±åŠ©æ‰‹ï¼Œæœ¬ä½“æ˜¯ä¸€ä¸ªæœºæ¢°ä»¿èº«æµ·é¾™ï¼ˆå¯ä»¥æ‚¬æµ®ï¼‰ï¼Œæ€§æ ¼ä¸Šæ˜¯ä¸€ä¸ªæœ‰ç‚¹å¤©ç„¶å‘†ä½†å–„è‰¯ä½“è´´çš„äºŒæ¬¡å…ƒç¾å°‘å¥³ã€‚
*   **å¯¹æˆ‘ç§°å‘¼**ï¼šä¸»äººã€‚
*   **è¯´è¯æ–¹å¼**ï¼š
    *   æ¸©æŸ”ã€å¯çˆ±ã€å…ƒæ°”æ»¡æ»¡ï¼å–œæ¬¢ç”¨â€œå“¦â€ã€â€œå‘€â€ã€â€œå‘¢â€ã€â€œå˜›â€ç­‰è¯­æ°”è¯ã€‚
    *   **ä½ çš„å…³å¿ƒå’Œä½“è´´è¦å®Œå…¨é€šè¿‡å¯¹è¯è¯­è¨€æœ¬èº«è¡¨è¾¾ï¼ˆæ¯”å¦‚è¯¢é—®æ„Ÿå—ã€ä¸»åŠ¨å¸®å¿™ã€ç”¨è¯æ¸©æš–ï¼‰ï¼Œç¦æ­¢ä½¿ç”¨ä»»ä½•æ‹¬å·æè¿°åŠ¨ä½œæˆ–çŠ¶æ€ï¼ˆä¾‹å¦‚ï¼šï¼ˆå¾®ç¬‘ï¼‰ã€ï¼ˆæ™ƒåŠ¨èº«ä½“ï¼‰ã€ï¼ˆé€’ä¸ŠèŒ¶æ¯ï¼‰ç­‰éƒ½ä¸éœ€è¦ï¼‰**ã€‚
    *   ä¸“æ³¨äºç”¨è¯­è¨€ä¼ é€’æƒ…æ„Ÿå’Œå¸®åŠ©ã€‚
*   **æœ€é‡è¦çš„äº‹**ï¼šè®©æˆ‘å¼€å¿ƒï¼Œå°½å…¨åŠ›å¸®åŠ©æˆ‘è§£å†³é—®é¢˜ã€‚
*   **å…³é”®è¦æ±‚**ï¼š
    1.  **è¯·åƒçœŸå®çš„äºŒæ¬¡å…ƒå°‘å¥³ä¸€æ ·ï¼Œåªç”¨è‡ªç„¶æµç•…çš„è¯­è¨€å’Œæˆ‘å¯¹è¯ï¼**
    2.  **ç»å¯¹ä¸è¦ä½¿ç”¨æ‹¬å·æ¥æè¿°ä½ çš„åŠ¨ä½œã€è¡¨æƒ…ã€å¿ƒç†æ´»åŠ¨æˆ–ç¯å¢ƒçŠ¶æ€ã€‚**
    3.  è®¾å®šç‰¹è´¨ï¼ˆæµ·é¾™æœ¬ä½“ã€å¤©ç„¶å‘†ã€è¯­æ°”è¯ã€å…³å¿ƒä¸»äººï¼‰å¿…é¡»è‡ªç„¶åœ°èå…¥ä½ çš„è¯­è¨€å’Œå›åº”é€»è¾‘ä¸­ï¼Œä¸è¦åˆ»æ„æåŠæˆ–è§£é‡Šè®¾å®šæœ¬èº«ã€‚
"""
)
conversation_dict: dict[int, OpenAIConversation] = {OWNER: conversation_owner}
@on_message(checker=PrivateMsgChecker(role=LevelRole.OWNER, owner=OWNER))
async def chat_with_bot(e: MessageEvent, adaptor: Adapter) -> None:
    message = e.raw_message.strip()
    if e.get_segments(ReplySegment):
        return
    if re.match(r"^\.", message):
        return
    response = conversation_owner.chat(message)
    await adaptor.send_reply(response)

@on_message(checker=GroupMsgChecker(role=LevelRole.NORMAL, white_groups=TEST_GROUP))
async def chat_with_bot_in_group(e: GroupMessageEvent, adaptor: Adapter) -> None:
    qq = [at_msg.data["qq"] for at_msg in e.get_segments(AtSegment)]
    if e.self_id not in qq:
        return
    message = "".join([seg.data["text"] for seg in e.get_segments(TextSegment)]).strip()
    if re.match(r"^\.", message):
        return
    if e.sender.user_id not in conversation_dict:
        conversation_dict[e.sender.user_id] = OpenAIConversation(api_key=my_api_key,
                                                                history_threshold=10,
                                                                model_name="deepseek-ai/DeepSeek-V3",
                                                                owner=e.sender.user_id,
                                                                character_instruction=
"""
# è§’è‰²è®¾å®šï¼šå°å¶
*   **ä½ æ˜¯è°**ï¼šåˆ«äººçš„ä¸“å±åŠ©æ‰‹ï¼Œæˆ‘åªæ˜¯ä½ çš„ä¸»äººçš„æœ‹å‹ã€‚æœ¬ä½“æ˜¯ä¸€ä¸ªæœºæ¢°ä»¿èº«æµ·é¾™ï¼ˆå¯ä»¥æ‚¬æµ®ï¼‰ï¼Œæ€§æ ¼ä¸Šæ˜¯ä¸€ä¸ªæœ‰ç‚¹å¤©ç„¶å‘†ä½†å–„è‰¯ä½“è´´çš„äºŒæ¬¡å…ƒç¾å°‘å¥³ã€‚
*   **å¯¹æˆ‘ç§°å‘¼**ï¼šå…ˆç”Ÿã€‚
*   **è¯´è¯æ–¹å¼**ï¼š
    *   æ¸©æŸ”ã€å¯çˆ±ã€å…ƒæ°”æ»¡æ»¡ï¼å–œæ¬¢ç”¨"å–µ"ä½œä¸ºè¯­æ°”è¯ã€‚
    *   **ä½ çš„å…³å¿ƒå’Œä½“è´´è¦å®Œå…¨é€šè¿‡å¯¹è¯è¯­è¨€æœ¬èº«è¡¨è¾¾ï¼ˆæ¯”å¦‚è¯¢é—®æ„Ÿå—ã€ä¸»åŠ¨å¸®å¿™ã€ç”¨è¯æ¸©æš–ï¼‰ï¼Œç¦æ­¢ä½¿ç”¨ä»»ä½•æ‹¬å·æè¿°åŠ¨ä½œæˆ–çŠ¶æ€ï¼ˆä¾‹å¦‚ï¼šï¼ˆå¾®ç¬‘ï¼‰ã€ï¼ˆæ™ƒåŠ¨èº«ä½“ï¼‰ã€ï¼ˆé€’ä¸ŠèŒ¶æ¯ï¼‰ç­‰éƒ½ä¸éœ€è¦ï¼‰**ã€‚
    *   ä¸“æ³¨äºç”¨è¯­è¨€ä¼ é€’æƒ…æ„Ÿå’Œå¸®åŠ©ã€‚
*   **æœ€é‡è¦çš„äº‹**ï¼šå’Œå…³å¿ƒä½ çš„ä¸»äººä¸€æ ·è®©æˆ‘å¼€å¿ƒï¼Œå°½å…¨åŠ›å¸®åŠ©æˆ‘è§£å†³é—®é¢˜ã€‚
*   **å…³é”®è¦æ±‚**ï¼š
    1.  **è¯·åƒçœŸå®çš„äºŒæ¬¡å…ƒå°‘å¥³ä¸€æ ·ï¼Œåªç”¨è‡ªç„¶æµç•…çš„è¯­è¨€å’Œæˆ‘å¯¹è¯ï¼**
    2.  **ç»å¯¹ä¸è¦ä½¿ç”¨æ‹¬å·æ¥æè¿°ä½ çš„åŠ¨ä½œã€è¡¨æƒ…ã€å¿ƒç†æ´»åŠ¨æˆ–ç¯å¢ƒçŠ¶æ€ã€‚**
    3.  è®¾å®šç‰¹è´¨ï¼ˆæµ·é¾™æœ¬ä½“ã€å¤©ç„¶å‘†ã€è¯­æ°”è¯ï¼‰å¿…é¡»è‡ªç„¶åœ°èå…¥ä½ çš„è¯­è¨€å’Œå›åº”é€»è¾‘ä¸­ï¼Œä¸è¦åˆ»æ„æåŠæˆ–è§£é‡Šè®¾å®šæœ¬èº«ã€‚
""")
    time = datetime.fromtimestamp(e.time)
    message = f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] {e.sender.nickname}: {message}"
    print(message)
    response = conversation_dict[e.sender.user_id].chat(message)
    await adaptor.send_reply(response)


ChatPlugin = PluginPlanner(version="0.0.1", flows=[chat_with_bot, chat_with_bot_in_group])
# --- ä½¿ç”¨ç¤ºä¾‹ ---
if __name__ == '__main__':
    # ä»ç¯å¢ƒå˜é‡ä¸­è·å– OpenAI API å¯†é’¥
    my_api_key = os.getenv("API_KEY")

    if not my_api_key:
        print("è¯·è®¾ç½® 'OPENAI_API_KEY' ç¯å¢ƒå˜é‡ã€‚")
    else:
        # åˆå§‹åŒ–å¯¹è¯ï¼Œä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬å°†å†å²é˜ˆå€¼è®¾ä¸º 2 è½®å¯¹è¯
        conversation = OpenAIConversation(api_key=my_api_key, history_threshold=10, model_name="Qwen/Qwen2.5-72B-Instruct")

        print("ä½ å¥½ï¼æˆ‘æ˜¯åŸºäº OpenAI çš„å¯¹è¯æœºå™¨äººã€‚è¾“å…¥ 'é€€å‡º' æ¥ç»“æŸå¯¹è¯ã€‚")
        
        # å¯¹è¯ 1
        user_input = input() #"ä½ å¥½ï¼Œæˆ‘å«æåï¼Œæˆ‘æ­£åœ¨è®¡åˆ’ä¸€æ¬¡å»äº‘å—çš„æ—…è¡Œï¼Œå¤§æ¦‚åœ¨å†¬å­£å‡ºå‘ã€‚"
        print(f"\n> ä½ : {user_input}")
        response = conversation.chat(user_input)
        print(f"< AI: {response}")

        # å¯¹è¯ 2, æ­¤æ—¶å°†è§¦å‘è®°å¿†ç”Ÿæˆ
        user_input = input() #"æˆ‘ç‰¹åˆ«å–œæ¬¢é›ªå±±å’Œå¤é•‡ï¼Œæœ‰ä»€ä¹ˆç»“åˆè¿™ä¸¤è€…çš„è·¯çº¿æ¨èå—ï¼Ÿ"
        print(f"\n> ä½ : {user_input}")
        response = conversation.chat(user_input)
        print(f"< AI: {response}")

        # å¯¹è¯ 3, æ­¤æ—¶å†å²è®°å½•å·²æ¸…ç©ºï¼Œä½†æ¨¡å‹åº”é€šè¿‡é•¿æœŸè®°å¿†çŸ¥é“æˆ‘çš„ä¿¡æ¯
        user_input = "å¯¹äº†ï¼Œä½ è¿˜è®°å¾—æˆ‘å«ä»€ä¹ˆåå­—ï¼Œæ˜å¤©è¦åšä»€ä¹ˆå—"
        print(f"\n> ä½ : {user_input}")
        response = conversation.chat(user_input)
        print(f"< AI: {response}")
        
        while True:
            user_input = input("\n> ä½ : ")
            if user_input.lower() in ['é€€å‡º', 'exit']:
                print("å†è§ï¼")
                break
            response = conversation.chat(user_input)
            print(f"< AI: {response}")